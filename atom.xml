<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://Yanoona.github.io</id>
    <title>|ω･`)暗中观察</title>
    <updated>2020-11-24T02:29:38.472Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://Yanoona.github.io"/>
    <link rel="self" href="https://Yanoona.github.io/atom.xml"/>
    <subtitle>大爷不进来看看吗？这里有好康的哦~~~</subtitle>
    <logo>https://Yanoona.github.io/images/avatar.png</logo>
    <icon>https://Yanoona.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, |ω･`)暗中观察</rights>
    <entry>
        <title type="html"><![CDATA[Java8 Stream流学习笔记]]></title>
        <id>https://Yanoona.github.io/2rO0MFRF0/</id>
        <link href="https://Yanoona.github.io/2rO0MFRF0/">
        </link>
        <updated>2020-06-29T06:12:18.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="流简介">流简介</h2>
<h3 id="1流是什么">1.流是什么？</h3>
<blockquote>
<p>流到底是什么呢🍧？简短的定义就是“ 从支持<strong>数据处理操作</strong>的<strong>源</strong>生成的<strong>元素序列</strong> ”</p>
</blockquote>
]]></summary>
        <content type="html"><![CDATA[<h2 id="流简介">流简介</h2>
<h3 id="1流是什么">1.流是什么？</h3>
<blockquote>
<p>流到底是什么呢🍧？简短的定义就是“ 从支持<strong>数据处理操作</strong>的<strong>源</strong>生成的<strong>元素序列</strong> ”</p>
</blockquote>
<!-- more -->
<ul>
<li>元素序列：就像集合一样，流也提供了一个接口，可以访问特定元素类型的一组有序值。但流的目的在于表达计算，比如filter、sorted和map。集合讲的事数据，流讲的是计算。</li>
<li>源：流会使用一个提供数据的源，如集合、数组或者输入/输出资源。</li>
<li>数据处理操作：流的数据处理功能支持类似于数据库的操作，以及函数式编程语言中的常用操作，如filter、map、reduce、find、match、sort等。流操作可以顺序执行，也可以并行执行。</li>
</ul>
<p>流操作两个重要的特点：</p>
<ol>
<li>流水线：很多流操作本身会返回一个流，这样多个操作就可以链接起来，形成一个大的流水线。</li>
<li>内部迭代：与使用迭代器显示迭代的集合不同，流的迭代操作是在背后进行的。</li>
</ol>
<h3 id="2流与集合">2.流与集合</h3>
<blockquote>
<p>流与集合之间的差异在于<strong>什么时候进行计算</strong>。</p>
</blockquote>
<p>集合是一个内存中的数据结构，它包含数据结构中目前所有的值——集合中的每个元素都得先算出来才能添加到集合中。（集合中的每个元素都是放在内存里的，元素都得先算出来才能成为集合的一部分。）</p>
<p>流是在概念上固定的数据结构（你不能添加或删除元素），其元素则是<strong>按需计算的</strong>。（流就像是一个延迟创建的集合：只有在消费者要求的时候才会计算值。）</p>
<h4 id="21-流只能遍历一次">2.1 流只能遍历一次</h4>
<p><mark>和迭代器类似，流只能遍历一次。遍历完之后，我们就说这个流已经被消费掉了。</mark></p>
<p>就比如下面这段代码：</p>
<pre><code class="language-java">List&lt;String&gt; title = Arrays.asList(&quot;Java8&quot;,&quot;In&quot;,&quot;Action&quot;);
Stream&lt;String&gt; s = title.stream();
s.forEach(System.out::println);
//到这里就会报出异常：流已被操作或者关闭
s.forEach(System.out::println);
</code></pre>
<h3 id="3-外部迭代与内部迭代">3. 外部迭代与内部迭代</h3>
<blockquote>
<p>使用Collection接口需要用户去做迭代（比如用for-each），这称为外部迭代。相反，Streams库使用<strong>内部迭代</strong>——它帮你把迭代做了，还把得到的流值存在了某个地方，你只要给出一个函数说要干什么就可以了。</p>
</blockquote>
<h4 id="31-使用内部迭代的原因">3.1 使用内部迭代的原因</h4>
<p>内部迭代时，项目可以透明的并行处理，或者用更优化的顺序进行处理。</p>
<p>Streams库的内部迭代可以自动选择一种适合硬件的数据表示和并行实现。与此相反，一旦通过写for-each而选择了外部迭代，那你基本上就要自己管理所有的并行问题了（<em>自己管理</em>实际上意味着“某个良辰吉日我们会把它并行化”或者“开始了关于人物和synchronized的漫长二而艰苦的斗争”。）</p>
<figure data-type="image" tabindex="1"><img src="https://Yanoona.github.io/post-images/1593411345757.png" alt="" loading="lazy"></figure>
<h3 id="4-流操作">4. 流操作</h3>
<blockquote>
<p>可以连接起来的流操作称为<strong>中间操作</strong>，关闭流的操作称为<strong>终端操作</strong>。</p>
</blockquote>
<h4 id="41-中间操作">4.1 中间操作</h4>
<p>诸如filter或sorted等中间操作会返回另一个流。折让多个操作可以链接起来形成一个查询。重要的是，<mark>除非流水线上出发一个终端操作，否则中间操作不会执行任何处理——它们很懒。</mark></p>
<h4 id="42-终端操作">4.2 终端操作</h4>
<p>终端操作会从流的流水线生成结果。其结果是任何不是流的值，比如List、Integer，甚至是void。</p>
<h4 id="43-使用流">4.3 使用流</h4>
<blockquote>
<p>总而言之，流的使用一般包括三件事：</p>
<ol>
<li>一个数据源（如集合）来执行一个查询；</li>
<li>一个中间操作链，形成一条流的流水线；</li>
<li>一个终端操作，执行流水线，并能生成结果；</li>
</ol>
</blockquote>
<p>中间操作：</p>
<table>
<thead>
<tr>
<th style="text-align:center">操作</th>
<th style="text-align:center">类型</th>
<th style="text-align:center">返回类型</th>
<th style="text-align:center">操作参数</th>
<th style="text-align:center">函数描述符</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">filter</td>
<td style="text-align:center">中间</td>
<td style="text-align:center">Stream<T></td>
<td style="text-align:center">Predicate<T></td>
<td style="text-align:center">T -&gt; boolean</td>
</tr>
<tr>
<td style="text-align:center">map</td>
<td style="text-align:center">中间</td>
<td style="text-align:center">Stream<R></td>
<td style="text-align:center">Funcation&lt;T，R&gt;</td>
<td style="text-align:center">T -&gt; R</td>
</tr>
<tr>
<td style="text-align:center">limit</td>
<td style="text-align:center">中间</td>
<td style="text-align:center">Stream<T></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">sorted</td>
<td style="text-align:center">中间</td>
<td style="text-align:center">Stream<T></td>
<td style="text-align:center">Comparator<T></td>
<td style="text-align:center">(T，T) -&gt; int</td>
</tr>
<tr>
<td style="text-align:center">distinct</td>
<td style="text-align:center">中间</td>
<td style="text-align:center">Stream<T></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<p>终端操作：</p>
<table>
<thead>
<tr>
<th style="text-align:center">操作</th>
<th style="text-align:center">类型</th>
<th style="text-align:center">目的</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">forEach</td>
<td style="text-align:center">终端</td>
<td style="text-align:center">消费流中的每个元素并对其应用Lambda。这一操作返回void</td>
</tr>
<tr>
<td style="text-align:center">count</td>
<td style="text-align:center">终端</td>
<td style="text-align:center">返回流中元素的个数。这一操作返回long</td>
</tr>
<tr>
<td style="text-align:center">collect</td>
<td style="text-align:center">终端</td>
<td style="text-align:center">把流归约成一个集合，比如List、Map甚至是Integer。</td>
</tr>
</tbody>
</table>
<h3 id="小结">小结</h3>
<ol>
<li>流是“ 从支持数据处理操作的源生成的一系列元素 ”。</li>
<li>流利用内部迭代：迭代通过filter、map、sorted等操作被抽象掉了。</li>
<li>流操作有两类：中间操作和终端操作（也就终止操作）。</li>
<li>filter和map等中间操作会返回一个流，并可以链接在一起。可以把它们设置成一条流水线，但并不会生成任何结果。</li>
<li>forEach和count等终端操作会返回一个非流的值，并处理流水线以返回结果。</li>
<li>流中的元素是按需计算的。</li>
</ol>
<hr>
<h2 id="使用流">使用流</h2>
<h3 id="1-筛选和切片">1. 筛选和切片</h3>
<h4 id="11-谓词筛选">1.1 谓词筛选</h4>
<blockquote>
<p>Stream接口支持filter方法。该操作会接收一个谓词（一个返回boolean的函数）作为参数，并返回一个包括所有符合谓词的元素的流</p>
</blockquote>
<p>代码示例：</p>
<pre><code class="language-java">List&lt;Dish&gt; vegetarianMenu = menu.stream().filter(Dish::isVegetarian).collect(toList());
</code></pre>
<h4 id="12-筛选各异元素去重">1.2 筛选各异元素（去重）</h4>
<p><mark>使用<code>distinct()</code>方法。</mark></p>
<h4 id="13-截短流">1.3 截短流</h4>
<blockquote>
<p>流支持==<strong>limit(n)</strong>==方法，该方法会返回一个不超过给定长度的流。所需的长度做为参数传递给limit。如果流是有序的，则最多会返回前n个元素。</p>
</blockquote>
<h4 id="14-跳过元素">1.4 跳过元素</h4>
<blockquote>
<p>流支持==<strong>skip(n)</strong>==方法，该方法会返回一个扔4</p>
<p>掉前n个元素的流。如果流中元素不足n个，则返回一个空值。</p>
</blockquote>
<h3 id="2-映射">2. 映射</h3>
<p>map</p>
<blockquote>
<p>流支持<strong>map</strong>方法，它会接收一个函数做为参数。这个函数会被应用到每个元素上，并将其映射成一个新的元素 （使用映射一次，是因为它和转换类似，但其中的细微差别在于它是**“创建一个新版本”而不是去“修改”**）。</p>
</blockquote>
<p>flatMap</p>
<blockquote>
<p>流支持flatMap方法，它的效果是，把一个流中的每个值都换成另一个流，然后把所有的流连接起来成为一个流。</p>
</blockquote>
<h3 id="3查找和匹配">3.查找和匹配</h3>
<h4 id="31-检查谓词是否至少匹配一个元素">3.1 检查谓词是否至少匹配一个元素</h4>
<p>使用==<strong>anyMatch</strong>==方法。anyMatch方法返回一个boolean，因此是一个终端操作。</p>
<h4 id="32-检查谓词是否匹配所有元素">3.2 检查谓词是否匹配所有元素</h4>
<p>使用==<strong>allMatch</strong>==方法。它的工作原理和anyMatch类似，但它会看看流中的元素是否<strong>都能</strong>匹配给定的谓词。</p>
<p>其中和allMatch相对的是==<strong>noneMatch</strong>==。它可以确保流中没有任何元素与给定的谓词匹配。</p>
<p><mark>注意：anyMatch、allMatch和noneMatch这三个操作都用到了我们所谓的<strong>短路</strong>，这就是大家熟悉的Java中&amp;&amp;和||运算符短路在流中的版本。</mark></p>
<blockquote>
<p><strong>短路求值：</strong></p>
<p>​         对于流而言，某些操作（例如allMatch、anyMatch、noneMatch、findFirst和findAny）不用处理整个流就能得到结果。只要找到一个元素，就可以有结果了。同样，limit也是一个短路操作：它只需要创建一个给定大小的流，而用不着处理流中所有的元素。在碰到无限大小的流的时候，这种操作就有用了：它们可以把<strong>无限流</strong>变成<strong>有限流</strong>。</p>
</blockquote>
<h4 id="33-查找元素">3.3 查找元素</h4>
<p>==<strong>findAny</strong>==方法将返回当前流中的任意元素。</p>
<p>其中这里涉及到<strong>Optional</strong>函数，以下为Optional简介：</p>
<blockquote>
<p>Optional<T>类（java.util.Optional）是一个容器类，代表一个值存在或不存在。findAny有时候可能什么元素都没找到。Java8的库设计人员引入了Optional<T>，这样就不用返回众所周知容易出问题的null了。</p>
</blockquote>
<p>Optional常用检查方法说明：</p>
<ul>
<li>isPresent（）将在Optional包含值的时候返回true，否则返回false。</li>
<li>ifPresent（Consumer<T> block）会在值存在的时候执行给定的代码块。</li>
<li>T get（）会在只存在时返回值，否则抛出一个NoSuchElement异常。</li>
<li>T orElse（T other）会在值存在时返回值，否则返回一个默认值。</li>
</ul>
<hr>
<h3 id="4-到目前为止所学习的中间操作和终端操作记录">4. 到目前为止所学习的中间操作和终端操作记录</h3>
<table>
<thead>
<tr>
<th style="text-align:center">操作</th>
<th style="text-align:center">类型</th>
<th style="text-align:center">返回类型</th>
<th style="text-align:center">操作参数</th>
<th style="text-align:center">函数描述符</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">filter</td>
<td style="text-align:center">中间</td>
<td style="text-align:center">Stream<T></td>
<td style="text-align:center">Predicate<T></td>
<td style="text-align:center">T -&gt; boolean</td>
</tr>
<tr>
<td style="text-align:center">map</td>
<td style="text-align:center">中间</td>
<td style="text-align:center">Stream<R></td>
<td style="text-align:center">Funcation&lt;T，R&gt;</td>
<td style="text-align:center">T -&gt; R</td>
</tr>
<tr>
<td style="text-align:center">limit</td>
<td style="text-align:center">中间（有状态-有界）</td>
<td style="text-align:center">Stream<T></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">sorted</td>
<td style="text-align:center">中间</td>
<td style="text-align:center">Stream<T></td>
<td style="text-align:center">Comparator<T></td>
<td style="text-align:center">(T，T) -&gt; int</td>
</tr>
<tr>
<td style="text-align:center">distinct</td>
<td style="text-align:center">中间（有状态-无界）</td>
<td style="text-align:center">Stream<T></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">skip</td>
<td style="text-align:center">中间（有状态-有界）</td>
<td style="text-align:center">Stream<T></td>
<td style="text-align:center">long</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">flatMap</td>
<td style="text-align:center">中间</td>
<td style="text-align:center">Stream<R></td>
<td style="text-align:center">Funcation&lt;T,Stream<R>&gt;</td>
<td style="text-align:center">T -&gt; boolean</td>
</tr>
<tr>
<td style="text-align:center">anyMatch</td>
<td style="text-align:center">终端</td>
<td style="text-align:center">boolean</td>
<td style="text-align:center">Predicate<T></td>
<td style="text-align:center">T -&gt; boolean</td>
</tr>
<tr>
<td style="text-align:center">noneMatch</td>
<td style="text-align:center">终端</td>
<td style="text-align:center">boolean</td>
<td style="text-align:center">Predicate<T></td>
<td style="text-align:center">T -&gt; boolean</td>
</tr>
<tr>
<td style="text-align:center">allMatch</td>
<td style="text-align:center">终端</td>
<td style="text-align:center">boolean</td>
<td style="text-align:center">Predicate<T></td>
<td style="text-align:center">T -&gt; boolean</td>
</tr>
<tr>
<td style="text-align:center">findAny</td>
<td style="text-align:center">终端</td>
<td style="text-align:center">Optional<T></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">findFirst</td>
<td style="text-align:center">终端</td>
<td style="text-align:center">Optional<T></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">forEach</td>
<td style="text-align:center">终端</td>
<td style="text-align:center">void</td>
<td style="text-align:center">Consumer<T></td>
<td style="text-align:center">T -&gt; void</td>
</tr>
<tr>
<td style="text-align:center">collect</td>
<td style="text-align:center">终端</td>
<td style="text-align:center">R</td>
<td style="text-align:center">Collector&lt;T，A，R&gt;</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">reduce</td>
<td style="text-align:center">终端（有状态-有界）</td>
<td style="text-align:center">Optional<T></td>
<td style="text-align:center">BinaryOperator</td>
<td style="text-align:center">（T，T） -&gt; T</td>
</tr>
<tr>
<td style="text-align:center">count</td>
<td style="text-align:center">终端</td>
<td style="text-align:center">long</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<p>更新时间：2020/6/29</p>
<!-- more -->
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spring 知识回顾之 体系结构]]></title>
        <id>https://Yanoona.github.io/ta0wVkBzF/</id>
        <link href="https://Yanoona.github.io/ta0wVkBzF/">
        </link>
        <updated>2020-05-13T04:41:46.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="一-体系结构">一、体系结构</h2>
<p>Spring 大概提供了20个左右的应用模块，可以根据应用程序的需求来进行使用。</p>
]]></summary>
        <content type="html"><![CDATA[<h2 id="一-体系结构">一、体系结构</h2>
<p>Spring 大概提供了20个左右的应用模块，可以根据应用程序的需求来进行使用。</p>
<!-- more -->
<figure data-type="image" tabindex="1"><img src="https://Yanoona.github.io/post-images/1589359363971.png" alt="Spring 架构图" loading="lazy"></figure>
<h2 id="二-核心容器">二、核心容器</h2>
<blockquote>
<p>核心容器由<strong>spring-core，spring-beans，spring-context，spring-context-support和spring-expression</strong>（SpEL，Spring表达式语言，Spring Expression Language）等模块组成，它们的细节如下：</p>
</blockquote>
<ul>
<li>
<p><strong>spring-core</strong>模块提供了框架的基本组成部分，包括 **控制反转（IOC）<strong>和</strong>依赖注入（DI）**功能。</p>
</li>
<li>
<p><strong>spring-beans</strong> 模块提供 BeanFactory，工厂模式的微妙实现，它移除了编码式单例的需要，并且可以把配置和依赖从实际编码逻辑中解耦。</p>
</li>
<li>
<p><strong>spring-context</strong> 模块建立在由<strong>core</strong>和 <strong>beans</strong> 模块的基础上建立起来的，它以一种类似于JNDI注册的方式访问对象。Context模块继承自Bean模块，并且添加了国际化（比如，使用资源束）、事件传播、资源加载和透明地创建上下文（比如，通过Servelet容器）等功能。Context模块也支持Java EE的功能，比如<code>EJB（Enterprise Java Beans的缩写，企业级JavaBean）</code>、<code>JMX（Java Management Extensions，即Java管理扩展）</code>和远程调用等。<strong>ApplicationContext</strong>接口是Context模块的焦点。</p>
</li>
<li>
<p><strong>spring-context-support</strong>提供了对第三方库集成到Spring上下文的支持，比如缓存（EhCache, Guava, JCache）、邮件（JavaMail）、调度（CommonJ, Quartz）、模板引擎（FreeMarker, JasperReports, Velocity）等。</p>
</li>
<li>
<p><strong>spring-expression</strong>模块提供了强大的表达式语言，用于在运行时查询和操作对象图。它是JSP2.1规范中定义的统一表达式语言的扩展，支持set和get属性值、属性赋值、方法调用、访问数组集合及索引的内容、逻辑算术运算、命名变量、通过名字从Spring IoC容器检索对象，还支持列表的投影、选择以及聚合等。</p>
</li>
</ul>
<hr>
<p>它们的完整依赖关系如下图所示：</p>
<figure data-type="image" tabindex="2"><img src="https://Yanoona.github.io/post-images/1589359408576.png" alt="Spring 体系结构" loading="lazy"></figure>
<h2 id="三-层级">三、层级</h2>
<h3 id="数据访问层集成层">数据访问层/集成层</h3>
<p>数据访问层包括 JDBC（ Java Data Base Connectivity ）、ORM（ Object Relational Mapping ）、OXM （ Object XML Mapping ）、JMS （ Java Message Service ）和事务处理模块：</p>
<ul>
<li>JDBC ：提供了JDBC的抽象层，消除了冗长的JDBC编码和对数据库供应商特定错误代码的解析。</li>
<li>ORM ：提供了对流行的对象关系映射API的集成，包括 JPA、MyBatis、Hibernate等。通过此模块可以让这些ORM框架和Spring的其它功能整合。</li>
<li>OXM ：提供了对OXM实现的支持，例如XML Beans。</li>
<li>JMS   ：包含生产（produce）和消费（consume）消息的功能，从Spring4.1开始集成了spring-messagessing模块。</li>
<li>事务处理模块：为实现所有特殊接口类及所有的POJO支持编程式和声明式事务的管理。</li>
</ul>
<h3 id="web层">WEB层</h3>
<p>Web 层由 Web，Web-MVC，Web-Socket 和 Web-Portlet 组成，它们的细节如下：</p>
<ul>
<li><strong>Web</strong> 模块提供面向web的基本功能和面向web的应用上下文，比如多部分（multipart）文件上传功能、使用Servlet监听器初始化IoC容器等。它还包括HTTP客户端以及Spring远程调用中与web相关的部分。。</li>
<li><strong>Web-MVC</strong> 模块为web应用提供了模型视图控制（MVC）和REST Web服务的实现。Spring的MVC框架可以使领域模型代码和web表单完全地分离，且可以与Spring框架的其它所有功能进行集成。</li>
<li><strong>Web-Socket</strong> 模块为 WebSocket-based 提供了支持，而且在 web 应用程序中提供了客户端和服务器端之间通信的两种方式。</li>
<li><strong>Web-Portlet</strong> 模块提供了用于Portlet环境的MVC实现，并反映了spring-webmvc模块的功能。</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spring 知识回顾之 概念]]></title>
        <id>https://Yanoona.github.io/CpjS5YWXn/</id>
        <link href="https://Yanoona.github.io/CpjS5YWXn/">
        </link>
        <updated>2020-05-13T02:39:19.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="一-概述">一、概述</h2>
<h3 id="11-说明">1.1 说明</h3>
<ul>
<li>Spring 是最受欢迎的企业级Java应用程序开发框架</li>
</ul>
]]></summary>
        <content type="html"><![CDATA[<h2 id="一-概述">一、概述</h2>
<h3 id="11-说明">1.1 说明</h3>
<ul>
<li>Spring 是最受欢迎的企业级Java应用程序开发框架<!-- more -->
</li>
<li>Spring 框架是一个开源的Java项目，最初由 Rod Johnson 以及 Juergen Hoeller 等人开发编写，并且于2003年6月在 <a href="https://zh.wikipedia.org/wiki/Apache_License_2.0">Apache License 2.0</a> 许可下发布</li>
<li>Spring 是轻量级的框架，最初版本只有2M左右</li>
<li>Spring 的<strong>核心特性是可以用于开发任何Java程序，以及简化Java程序开发的复杂度</strong>。</li>
</ul>
<h3 id="12-好处">1.2 好处</h3>
<ul>
<li>方便解耦,简化开发</li>
<li>支持面相切面的编程,并且把应用业务逻辑和系统分开</li>
<li>包含并管理应用中对象的生命周期和配置</li>
<li>Spring 的 web 框架是一个设计良好的 web MVC 框架，它为比如 Structs 或者其他工程上的或者不怎么受欢迎的 web 框架提供了一个很好的供替代的选择。</li>
<li>Spring提供了一致的事务管理接口，可向下扩展到本地事务并扩展到全局事务</li>
</ul>
<h3 id="13-重点概念">1.3 重点概念</h3>
<h4 id="依赖注入dependency-injection简称di">依赖注入（Dependency Injection，简称<strong>DI</strong>）</h4>
<blockquote>
<p>Spring 最认同的技术是控制反转的**依赖注入（DI）**模式。控制反转（IoC）是一个通用的概念，它可以用许多不同的方式去表达，依赖注入仅仅是控制反转的一个具体的例子。</p>
<p>将依赖关系部分转化为两个类之间的关联。例如，类 A 依赖于类 B。现在，让我们看一看第二部分，注入。所有这一切都意味着类 B 将通过 IoC 被注入到类 A 中。</p>
<p>依赖注入可以以向构造函数传递参数的方式发生，或者通过使用 setter 方法 post-construction。</p>
</blockquote>
<p>一句话概括：<mark>创建被调用者实例的工作由Spring容器来完成，然后注入调用者，因此被称为<strong>依赖注入</strong>。</mark></p>
<hr>
<h4 id="控制反转inversion-of-control缩写为ioc">控制反转（Inversion of Control，缩写为<strong>IOC</strong>）</h4>
<blockquote>
<p><strong>控制反转（IOC）</strong>，是面向对象编程中的一种设计原则，可以用来减低代码之间的耦合度。其中最常见的方式叫做<strong>依赖注入（DI）</strong>，还有一种方式叫 “依赖查找”。通过控制反转，对象在被创建的时候，有一个调控系统内所有对象的外界实体，将其所依赖的对象的引用传递（注入）给它。</p>
</blockquote>
<p>一句话概括：<mark>创建被调用者的工作不再由调用者来完成，因此被称为<strong>控制反转（IOC）</strong>。</mark></p>
<hr>
<h4 id="面向切面aspect-oriented-programming缩写为aop">面向切面（Aspect-oriented programming，缩写为AOP）</h4>
<blockquote>
<p>**面向切面（AOP）**是计算机科学中的一种程序设计思想，<strong>目标在将横切关注点和业务主体进行进一步分离，以提高程序代码的模块化程度</strong>。</p>
</blockquote>
<p>AOP的概念点：</p>
<ul>
<li>关注点（Concern）：<em>对软件工程有意义的小的、可管理的、可描述的软件组成部分，一个关注点通常只同一个特定概念或目标相关联。</em></li>
<li>主关注点（Core concern）：<em>一个软件最主要的关注点。</em></li>
<li>关注点分离（Separation of concerns，SOC）：<em>标识、封装和操作关注点的能力。</em></li>
<li>方法（Method）：<em>用来描述、设计、实现一个给定关注点的软件构造单位。</em></li>
<li>横切（Crosscut）：<em>两个关注点相互横切，如果实现它们的方法存在交集。</em></li>
<li>支配性分解（Dominant decomposition）：<em>将软件分解成模块的主要方式。支配性分解一般是按主关注点进行模块分解的。</em></li>
<li>横切关注点（Crosscutting concerns）：<em>在传统的程序设计语言中，除了主关注点可以被支配性分解方式捕捉以外，还有许多没有被支配性分解方式捕捉到的关注点，这些关注点的实现会弥散在整个软件内部，这时这些关注点同主关注点是横切的。</em></li>
<li>切面（Aspect）：<em>在支配性分解的基础上，提供的一种辅助的模块化机制，这种新的模块化机制可以捕捉横切关注点。</em></li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java8日期API使用记录]]></title>
        <id>https://Yanoona.github.io/lIPSlIjZp/</id>
        <link href="https://Yanoona.github.io/lIPSlIjZp/">
        </link>
        <updated>2020-05-11T09:30:00.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="日期转换">日期转换</h2>
<h3 id="1date转换成localdate">1.Date转换成LocalDate</h3>
<p><strong>这里的 Date 为 <code>java.util</code>包下的 Date。</strong></p>
<h4 id="第一种方式">第一种方式：</h4>
]]></summary>
        <content type="html"><![CDATA[<h2 id="日期转换">日期转换</h2>
<h3 id="1date转换成localdate">1.Date转换成LocalDate</h3>
<p><strong>这里的 Date 为 <code>java.util</code>包下的 Date。</strong></p>
<h4 id="第一种方式">第一种方式：</h4>
<!-- more -->
<pre><code class="language-java">Date date = new Date();
//使用Date类中的toInstant方法转换成Time包中的Instant类
Instant instant = date.toInstant();
//因为转换后的Instant类不带有时区，所以为其添加时区
ZonedDateTime zonedDateTime = instant.atZone(ZoneId.systemDefault());
//调用toLocalDate方法转换成LocalDate
zonedDateTime.toLocalDate();
</code></pre>
<h4 id="第二种方式">第二种方式：</h4>
<pre><code class="language-java">Date date = new Date();
//先将其转换成 java.sql包的Date，因为此包下的Date类中带有 直接转换LocalDate 的方法
java.sql.Date sqlDate = new java.sql.Date(date.getTime());
LocalDate localDate = sqlDate.toLocalDate();
</code></pre>
<hr>
<h3 id="2date转换成localdate">2.Date转换成LocalDate</h3>
<p><strong>这里的 Date 为 <code>java.sql</code>包下的 Date。</strong></p>
<pre><code class="language-java">Date sqlDate = new Date(date.getTime());
LocalDate localDate = sqlDate.toLocalDate();
</code></pre>
<hr>
<h3 id="3timestamp转换为localdate">3.Timestamp转换为LocalDate</h3>
<pre><code class="language-java">Timestamp timestamp = new Timestamp(System.currentTimeMillis());
LocalDateTime localDateTime = timestamp.toLocalDateTime();
LocalDate localDate = localDateTime.toLocalDate();
</code></pre>
<h2 id="-more-"><!-- more --></h2>
<h4 id="4calendar转换为zonedatetime">4.Calendar转换为ZoneDateTime</h4>
<pre><code class="language-java">Calendar calendar = Calendar.getInstance();
//Calendar对象在Java1.1版本开始提供了一个方法用于获取时区对象getTimeZone方法
//转换需要先获取到时区信息
TimeZone timeZone = calendar.getTimeZone();
//自Java1.8版本开始，TimeZone类加入了一个方法可以获取到ZoneId
ZoneId zoneId = timeZone.toZoneId();
//使用ofInstant方法将Instant参数和时区封装成ZoneDateTime
ZonedDateTime zonedDateTime = ZonedDateTime.ofInstant(calendar.toInstant(),zoneId);
</code></pre>
<h2 id="日期的解析与格式化控制">日期的解析与格式化控制</h2>
<blockquote>
<p><code>SimpleDateFormat</code> 类是线程不安全的，所以 Java1.8 版本加入了 <code>DateTimeFormatter</code>.</p>
<p><code>DateTimeFormatter</code> 类提供了大量预定义格式化器，包括常量（如ISO_LOCAL_DATE），模式字母（如yyyy-MM-dd）以及本地化样式.</p>
<p><strong>与<code>SimpleDateFormat</code> 不同的是，新版本的日期/时间API的格式化与解析不需要在创建转换器对象再进行转换了，通过时间日期对象的<code>parse/format</code>方法可以直接进行转换.</strong></p>
</blockquote>
<h3 id="1格式控制-format-和解析-parse">1.格式控制 format 和解析 parse</h3>
<pre><code class="language-java">LocalDateTime localDateTime = LocalDateTime.now();
//使用format方法进行格式化处理
String dateTime = localDateTime.format(DateTimeFormatter.ISO_DATE);
System.out.println(dateTime);

//使用parse方法解析字符串为日期对象
//注意：此处的dateTime字符串经过上面的格式化的处理后是LocalDate格式.
//如果使用LocalDateTime接收，编译会通过，但会报出异常：
//		Process 'command 'C:/Java/jdk1.8.0_211/bin/java.exe'' finished with non-zero exit value 1
LocalDate localDate = LocalDate.parse(dateTime);
System.out.println(localDate);
</code></pre>
<hr>
<h3 id="2使用-oflocalizeddate-方法指定解析长度">2.使用 ofLocalizedDate 方法指定解析长度</h3>
<p><strong>此方法在不同时区有不同的解析格式</strong></p>
<pre><code class="language-java">String dateTime1 = localDateTime.format(DateTimeFormatter.ofLocalizedDate(FormatStyle.FULL));
String dateTime2 = localDateTime.format(DateTimeFormatter.ofLocalizedDate(FormatStyle.SHORT));
String dateTime3 = localDateTime.format(DateTimeFormatter.ofLocalizedDate(FormatStyle.MEDIUM));
String dateTime4 = localDateTime.format(DateTimeFormatter.ofLocalizedDate(FormatStyle.LONG));
//输出结果：FULL：2020年5月12日 星期二
System.out.println(&quot;FULL：&quot; + dateTime1);
//输出结果：SHORT：20-5-12
System.out.println(&quot;SHORT：&quot; + dateTime2);
//输出结果：MEDIUM：2020-5-12
System.out.println(&quot;MEDIUM：&quot; + dateTime3);
//输出结果：LONG：2020年5月12日
System.out.println(&quot;LONG：&quot; + dateTime4);
</code></pre>
<hr>
<h3 id="3自定义格式">3.自定义格式</h3>
<pre><code class="language-java">String datetime = localDateTime.format(DateTimeFormatter.ofPattern(&quot;yyyy/MM/dd HH:mm:ss:SSS&quot;));
//输出结果：LONG：2020/05/12 09:43:25:213
System.out.println(datetime);
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[CentOS 7定时执行Java程序]]></title>
        <id>https://Yanoona.github.io/XvCd5eo8U/</id>
        <link href="https://Yanoona.github.io/XvCd5eo8U/">
        </link>
        <updated>2020-02-27T08:26:32.000Z</updated>
        <content type="html"><![CDATA[<h2 id="概述">😀概述</h2>
<p>记录一次CentOS7中使用Crontab定时任务执行Java程序的操作。</p>
<h2 id="准备">😃准备</h2>
<ul>
<li>JAVA程序(可运行的Jar包)</li>
<li>CentOS系统</li>
<li>Crontab定时任务服务</li>
</ul>
<h2 id="步骤">😄步骤</h2>
<h3 id="将jar包上传到centos系统上">将Jar包上传到CentOS系统上</h3>
<blockquote>
<p>此步省略详细操作，简述大概步骤🤐。</p>
</blockquote>
<h4 id="建立平台连接">建立平台连接</h4>
<p>为以后方便在Windows系统和CentOS系统间的文件传输操作，此步建议搭建👨‍🔧 <code>ftp</code>服务器。</p>
<h4 id="打包java程序">打包Java程序</h4>
<p>Maven方式：</p>
<p>在项目中的<strong>pom.xml</strong>文件中，加入以下👇打包标签，之后再使用打包命令<code>mvn clean package</code>或者使用IDEA里的Maven插件。</p>
<pre><code class="language-xml">&lt;build&gt;
        &lt;!--使用Maven编译可执行的jar --&gt;
        &lt;finalName&gt;update_ase_cms&lt;/finalName&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;
                &lt;configuration&gt;
                    &lt;appendAssemblyId&gt;false&lt;/appendAssemblyId&gt;
                    &lt;descriptorRefs&gt;
                        &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;
                    &lt;/descriptorRefs&gt;
                    &lt;archive&gt;
                        &lt;manifest&gt;
                            &lt;mainClass&gt;{在这里填入你的启动类}&lt;/mainClass&gt;
                        &lt;/manifest&gt;
                    &lt;/archive&gt;
                &lt;/configuration&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;id&gt;make-assembly&lt;/id&gt;
                        &lt;phase&gt;package&lt;/phase&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;assembly&lt;/goal&gt;
                        &lt;/goals&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;

</code></pre>
<blockquote>
<p>如果运行Jar包后出现<code>java.lang.ClassNotFoundException</code>或者<code>no main manifest attribute</code>异常☹️的话，就是此处没有配置好。</p>
</blockquote>
<h4 id="将jar包上传到centos中">将Jar包上传到CentOS中</h4>
<p>此步骤使用 ftp 服务器上传即可😤。</p>
<hr>
<h3 id="crontab配置和使用">Crontab配置和使用</h3>
<h4 id="查看是否安装crontab">查看是否安装Crontab</h4>
<pre><code>rpm -qa | grep cron
</code></pre>
<p>已安装的为下图😋所示（一般来说，系统自带Crontab😉）：</p>
<figure data-type="image" tabindex="1"><img src="https://Yanoona.github.io/post-images/1582792080190.png" alt="" loading="lazy"></figure>
<h4 id="查看crontab是否开机自启及相关命令">查看Crontab是否开机自启及相关命令</h4>
<pre><code>#查看状态
systemctl status crond
#开启crontab服务
systemctl start crond
#关闭crontab服务
systemctl stop crond
#重启crontab服务
systemctl restart crond
#开机启动
systemctl enable crond
#删除开机启动
systemctl disable crond
</code></pre>
<h4 id="编写shell脚本">编写shell脚本</h4>
<p>注意：目录必须为👏绝对路径👏。（执行前请注意自己是否配置了Java环境，并且配置成功了）</p>
<pre><code class="language-shell">#创建shell脚本文件
vim {你的脚本文件名}.sh

#在文件中输入以下命令

#!/bin/bash
#写入环境变量
export LANG=&quot;en_US.UTF-8&quot;
export JAVA_HOME={这里放你的Java地址}
export PATH=$JAVA_HOME/bin:$PATH
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
java -jar {你上传的Jar包目录} &amp;&amp; echo &quot;开始执行项目！&quot;
echo &quot;【`date +%Y-%m-%d_%H:%M:%S`】完成！&quot;
</code></pre>
<h4 id="添加定时任务">添加定时任务</h4>
<p>打开定时任务编辑：</p>
<pre><code>crontab -e
</code></pre>
<p>在打开后的文本中编辑：</p>
<pre><code>*/1 * * * * {你的shell文件的绝对路径} &gt;&gt; {要将输出信息存储到日志文件的目录文件}
</code></pre>
<blockquote>
<ul>
<li>
<p>👩‍🏫👩‍🏫<code>{要将输出信息存储到日志文件的目录文件}</code>这里的意思就是<strong>每次执行时将shell脚本中的输出都追加到这个文件下</strong></p>
</li>
<li>
<p><code>*/1 * * * *</code>这里表示每隔1分钟就执行一次，具体用法如以下所示：</p>
</li>
</ul>
<p>⚡️<a href="https://www.e-learn.cn/content/qita/2644597">Crontab-易学教程</a> 或者 <a href="http://cron.qqe2.com/">Crontab表达式生成</a>⚡️</p>
</blockquote>
<h4 id="查看定时任务执行状态">查看定时任务执行状态</h4>
<h5 id="查看任务日志">查看任务日志：</h5>
<pre><code>tail -f /var/log/cron
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://Yanoona.github.io/post-images/1582792071997.png" alt="" loading="lazy"></figure>
<p>其中如<code>Feb 27 15:57:25 hadoop104 crontab[21024]: (hadoop) REPLACE (hadoop)</code>等信息的作用为（借大佬😎说的）：</p>
<blockquote>
<p>Cron程序自己的日志，像是Cron daemon刚启动的时候打印的信息，类似于报告版本之类的，这里说此版本的crond支持inotify特性，也就是说，可以自动监测配置文件的改变（利用OS的inotify接口）而<code>Feb 27 16:00:01 hadoop104 CROND[21454]: (root) CMD (/usr/lib64/sa/sa1 1 1)</code>的作用为：</p>
<p>Cron在某个时间点运行了某个Crontab里CMD，这里的CMD名字叫做sa，是系统信息收集的后端，请参见sar/sa<code>Feb 27 16:06:01 hadoop104 CROND[21644]: (hadoop) CMD (/usr/java_program/crontab_java.sh &gt;&gt; /usr/java_program/file)</code>这一类信息表示：</p>
</blockquote>
<blockquote>
<p>在这个时间段执行的定时任务。</p>
</blockquote>
<h5 id="查看执行了的定时任务信息">查看执行了的定时任务信息</h5>
<p>因为之前在定时任务编辑时，我们写了✏️<code>{你的shell文件的绝对路径} &gt;&gt; {要将输出信息存储到日志文件的目录文件}</code>。本步骤就是查看👉<code>{要将输出信息存储到日志文件的目录文件}</code>这个文件里的信息。</p>
<p>进入到这个目录，如我这里的 /usr/java_program/file 文件。</p>
<p>打开如下图所示，表明任务执行成功，没有报错。🌈🌈</p>
<figure data-type="image" tabindex="3"><img src="https://Yanoona.github.io/post-images/1582792045981.png" alt="" loading="lazy"></figure>
<hr>
<h3 id="使用总结">使用总结</h3>
<ol>
<li>打包的时候，先在本地测试jar包能不能运行，会不会报异常，确认没有问题之后，方可上传。</li>
<li>如果在集群环境下设置定时任务，最好先确保每台机子的时区、时间是否一致。</li>
<li>路径使用绝对路径编写。</li>
</ol>
<p>就先记录这么多了，还没碰到的异常就等到以后使用的在记录，GoodBye！</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[使用axios出现的跨域问题]]></title>
        <id>https://Yanoona.github.io/zxJ0ci4F1/</id>
        <link href="https://Yanoona.github.io/zxJ0ci4F1/">
        </link>
        <updated>2020-02-20T01:46:38.000Z</updated>
        <summary type="html"><![CDATA[<h3 id="前言">前言</h3>
<blockquote>
<p>最近在使用SpringBoot和Vue进行前后端分离开发😊，且测试功能时，出现了此异常😕：<br>
<code>CORS policy: No 'Access-Control-Allow-Origin' header is present on the requested resource.</code></p>
</blockquote>
]]></summary>
        <content type="html"><![CDATA[<h3 id="前言">前言</h3>
<blockquote>
<p>最近在使用SpringBoot和Vue进行前后端分离开发😊，且测试功能时，出现了此异常😕：<br>
<code>CORS policy: No 'Access-Control-Allow-Origin' header is present on the requested resource.</code></p>
</blockquote>
<!-- more -->
<blockquote>
<p>通过查看👀相关资料后发现是由于CORS跨越问题造成的，得知解决办法无非有两种方式：<strong>响应头添加参数和添加过滤器。</strong></p>
</blockquote>
<h3 id="什么是cors">什么是CORS</h3>
<blockquote>
<p>CORS，常被大家称之为跨越问题，准确的叫法是<strong>跨域资源共享（CORS，Cross-origin resource sharing）</strong>，是W3C标准，是一种机制，它使用额外的HTTP头来告诉浏览器 让运行在一个 origin (domain) 上的Web应用被准许访问来自不同源服务器上的指定的资源。☄当一个资源从与该资源本身所在的服务器不同的域或端口请求一个资源时，资源会发起一个跨域 HTTP 请求。</p>
</blockquote>
<h3 id="解决办法">解决办法👨‍🔧</h3>
<ul>
<li><strong>🚶‍♀使用过滤器</strong></li>
</ul>
<pre><code>@Configuration
public class AccessControlAllowOriginFilter extends WebMvcConfigurerAdapter {
    @Override
    public void addCorsMappings(CorsRegistry registry) {
        registry.addMapping(&quot;/*/**&quot;)
                .allowedOrigins(&quot;http://localhost:8080&quot;)
                .allowedMethods(&quot;GET&quot;, &quot;POST&quot;,&quot;UPDATE&quot;,&quot;DELETE&quot;)
                .allowCredentials(false).maxAge(3600);
    }
}
</code></pre>
<ul>
<li><strong>👫在需要的地方添加<code>CrossOrigin</code>注解</strong></li>
</ul>
<pre><code>@CrossOrigin(origins = &quot;http://192.168.1.97:8080&quot;, maxAge = 3600)
@RequestMapping(&quot;rest_index&quot;)
@RestController
public class IndexController{
</code></pre>
<ul>
<li><strong>👪添加响应头</strong></li>
</ul>
<blockquote>
<p>在被请求资源中添加响应头信息&quot;Access-Control-Allow-Origin：*</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Axios远程接口链接时，报404]]></title>
        <id>https://Yanoona.github.io/VOrX9Qjkt/</id>
        <link href="https://Yanoona.github.io/VOrX9Qjkt/">
        </link>
        <updated>2020-02-20T01:40:20.000Z</updated>
        <summary type="html"><![CDATA[<h3 id="前言">前言</h3>
<blockquote>
<p>刚刚在项目中使用Axios远程调用后端接口时，出现以下异常😫😫：<br>
<code>Uncaught (in promise) Error: Request failed with status code 404</code></p>
</blockquote>
]]></summary>
        <content type="html"><![CDATA[<h3 id="前言">前言</h3>
<blockquote>
<p>刚刚在项目中使用Axios远程调用后端接口时，出现以下异常😫😫：<br>
<code>Uncaught (in promise) Error: Request failed with status code 404</code></p>
</blockquote>
<!-- more -->
<h3 id="解决方法">解决方法</h3>
<p>将项目中的原Axios方法改造👨‍🔧如以下代码所示👇：<br>
<strong>改造前：</strong></p>
<pre><code> axios.post({
          url: &quot;这里是请求的的URL&quot;,
          timeout: 10000,
          //不带Cokkie
          withCredentials: false,
          headers: {
            &quot;Content-Type&quot;: &quot;application/x-www-form-urlencoded&quot;
          },
          data: {
            &quot;userName&quot;: this.username,
            &quot;passWord&quot;: this.password
          }
        }).then((res) =&gt; {
          console.log(res);
          if (res.data.status == 0) {
            this.$Message.info(&quot;得到信息&quot;);
          } else {
            this.$Message.warning(&quot;未得到信息&quot;);
          }
        })
</code></pre>
<p><strong>改造后：</strong></p>
<pre><code>var instance = axios.create({headers: {'content-type': 'application/x-www-form-urlencoded'}});
        instance.post(`这里是请求的的URL`, params).then((res) =&gt; {
          console.log(res);
        });
</code></pre>
<p>修改完后就可以成功链接了👏。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[使用Iview手脚架搭建项目异常]]></title>
        <id>https://Yanoona.github.io/Y72Yd1hiG/</id>
        <link href="https://Yanoona.github.io/Y72Yd1hiG/">
        </link>
        <updated>2020-02-20T01:37:08.000Z</updated>
        <summary type="html"><![CDATA[<h4 id="出现异常">出现异常</h4>
<blockquote>
<p>刚刚在使用iview手脚架搭建项目完成后，想着尝试启动项目看看，结果控制台报出了<code>TypeError [ERR_INVALID_CALLBACK]: Callback must be a function</code>异常😟。</p>
</blockquote>
]]></summary>
        <content type="html"><![CDATA[<h4 id="出现异常">出现异常</h4>
<blockquote>
<p>刚刚在使用iview手脚架搭建项目完成后，想着尝试启动项目看看，结果控制台报出了<code>TypeError [ERR_INVALID_CALLBACK]: Callback must be a function</code>异常😟。</p>
</blockquote>
<!-- more -->
<pre><code>TypeError [ERR_INVALID_CALLBACK]: Callback must be a function
    at maybeCallback (fs.js:128:9)
    at Object.write (fs.js:535:14)
    at G:\iviewEnd\webpack.prod.config.js:10:8
    at FSReqWrap.args [as oncomplete] (fs.js:140:20)
</code></pre>
<h4 id="解决异常">解决异常</h4>
<blockquote>
<p>在异常错误中定位到所发现异常的路径😃，如我这里的 <strong><code>G:\iviewEnd\webpack.prod.config.js:10:8</code></strong></p>
</blockquote>
<pre><code>fs.open('./src/config/env.js', 'w', function (err, fd) {
    const buf = 'export default &quot;production&quot;;';
    //fs.write(fd, buf, 0, buf.length, 0, function (err, written, buffer){});
    //将上面这一行修改为
    fs.write(fd, buf, 0, 'utf-8', function(err, written, buffer) {});
});
</code></pre>
<p>保存再次运行 <strong>npm run dev</strong> 即可启动项目👏。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sqoop的安装和使用]]></title>
        <id>https://Yanoona.github.io/vqAakgQmf/</id>
        <link href="https://Yanoona.github.io/vqAakgQmf/">
        </link>
        <updated>2020-02-19T07:27:57.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="概述">😀概述</h2>
<p>Sqoop 是 apache 旗下一款“Hadoop 和关系数据库服务器之间传送数据”的工具。<br>
核心的功能有两个：导入、导出<br>
本文档用于记录 Sqoop的安装和使用。</p>
]]></summary>
        <content type="html"><![CDATA[<h2 id="概述">😀概述</h2>
<p>Sqoop 是 apache 旗下一款“Hadoop 和关系数据库服务器之间传送数据”的工具。<br>
核心的功能有两个：导入、导出<br>
本文档用于记录 Sqoop的安装和使用。</p>
<!-- more -->
<blockquote>
<p>建议🗣<code>先配置好Hadoop的JobHistory节点</code>，以便于在Web中的Yarn界面查看MapReduce任务日志信息。</p>
</blockquote>
<h2 id="sqoop安装">😃Sqoop安装</h2>
<h3 id="1前提概述">1.前提概述</h3>
<blockquote>
<ul>
<li><strong>Sqoop就是一个工具， 只需要在一个节点上进行安装即可。</strong></li>
</ul>
<ul>
<li><strong>你安装的Sqoop软件的节点一定要包含你要使用的集群或者软件系统的安装包</strong></li>
</ul>
</blockquote>
<h3 id="2-软件下载">2. 软件下载</h3>
<p>下载地址：⚡️<a href="http://mirrors.hust.edu.cn/apache/sqoop/">点击此处打开Sqoop下载链接</a>⚡️</p>
<blockquote>
<p>注意👇：</p>
<ol>
<li>
<p>下载<code>sqoop-xx.bin__xx.tar.gz</code>的安装压缩包。</p>
</li>
<li>
<p>Sqoop 1 和Sqoop 2不兼容，且绝大部分企业所使用的Sqoop的版本是 Sqoop 1。</p>
<p>​	1.4.7版本的为Sqoop 1</p>
<p>​	1.99.7版本的为Sqoop 2</p>
</li>
</ol>
</blockquote>
<h2 id="安装">😄安装</h2>
<h3 id="1创建sqoop安装目录">1.创建sqoop安装目录</h3>
<pre><code>mkdir /usr/local/sqoop
</code></pre>
<h3 id="2解压安装包到指定目录">2.解压安装包到指定目录</h3>
<p>上传☝️解压缩安装包到指定目录（此处跳过了Ftp传输步骤）。</p>
<p>因为之前hive只是安装在hadoop1机器上，所以我这里Sqoop也同样安装在hadoop1机器上。👋</p>
<pre><code>tar -zxvf sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz /usr/local/sqoop
</code></pre>
<h3 id="3修改配置文件">3.修改配置文件</h3>
<ol>
<li>
<p>进入到 conf 文件夹中，复制sqoop-env-template.sh，并将其修改为sqoop-env.sh</p>
<pre><code>cp sqoop-env-template.sh sqoop-env.sh
</code></pre>
</li>
<li>
<p>修改sqoop-env.sh</p>
<pre><code>vi sqoop-env.sh
</code></pre>
<pre><code>export HADOOP_MAPRED_HOME=/usr/local/hadoop/hadoop-2.9.2			#Hadoop的MapReduce安装路径
export HADOOP_COMMON_HOME=/usr/local/hadoop/hadoop-2.9.2			#Hadoop的Common安装路径
export HIVE_HOME=/usr/local/hive/hive							  #Hive安装路径
</code></pre>
<p>🙄为什么在sqoop-env.sh 文件中会要求分别进行 common和mapreduce的配置呢？？？</p>
<blockquote>
<p>🙋在apache的hadoop的安装中；四大组件都是安装在同一个hadoop_home中的</p>
<p>🙋‍♂但是在CDH, HDP中， 这些组件都是可选的。</p>
<p>🙋在安装hadoop的时候，可以选择性的只安装HDFS或者YARN，</p>
<p>🙋‍♂CDH,HDP在安装hadoop的时候，会把HDFS和MapReduce有可能分别安装在不同的地方。</p>
</blockquote>
</li>
<li>
<p>将Mysql驱动包放到 lib 文件夹下</p>
<pre><code>cp mysql-connector-java-5.1.48-bin.jar /usr/local/sqoop/sqoop-1.4.7/lib/
</code></pre>
</li>
<li>
<p>配置环境变量</p>
<pre><code>vi /etc/profile
</code></pre>
<pre><code>#在末尾处添加以下行
export SQOOP_HOME=/usr/local/sqoop/sqoop-1.4.7
export PATH=${PATH}:${SQOOP_HOME}/bin
</code></pre>
<pre><code>#使文件生效
source /etc/profile
</code></pre>
</li>
<li>
<p>验证是否安装成功👨‍🔧</p>
<pre><code>sqoop version
</code></pre>
</li>
</ol>
<h2 id="sqoop的基本命令">😁Sqoop的基本命令</h2>
<pre><code>#查看命令
sqoop help

#运行结果：
usage: sqoop COMMAND [ARGS]

Available commands:
							#生成与数据库记录交互的代码
  codegen            Generate code to interact with database records
  							#将表定义导入到Hive中
  create-hive-table  Import a table definition into Hive
  							#计算一个SQL语句并显示结果，可以用来校验下import的查询条件是否正确。
  eval               Evaluate a SQL statement and display the results
  							#将HDFS目录导出到数据库表
  export             Export an HDFS directory to a database table
  							#可用命令列表
  help               List available commands
  							#将表从数据库导入到HDFS
  import             Import a table from a database to HDFS
  							#将所有表从数据库导入到HDFS
  import-all-tables  Import tables from a database to HDFS
  							#从大型机服务器导入数据集到HDFS
  import-mainframe   Import datasets from a mainframe server to HDFS
  							#将Import任务保存为job，可以理解为起了个别名，这样方便的Sqoop任务的管理。
  job                Work with saved jobs
  							#列出服务器上可用的数据库
  list-databases     List available databases on a server
  							#列出数据库上可用的b表
  list-tables        List available tables in a database
  							#增量导入的合并结果
  merge              Merge results of incremental imports
  							#运行一个独立的Sqoop metastore
  metastore          Run a standalone Sqoop metastore
  							#显示sqoop的版本
  version            Display version information

See 'sqoop help COMMAND' for information on a specific command.

</code></pre>
<h2 id="sqoop的基本使用">😆Sqoop的基本使用</h2>
<blockquote>
<p><strong>执行Sqoop命令时，请登录对hadoop有操作权限的系统用户🤴，否则会报没有权限等错误。</strong></p>
<p>以下命令中出现的<code>\</code>为连接符，连接下一句命令，在实际操作中也可使用。</p>
</blockquote>
<hr>
<h4 id="列出mysql中有哪些数据库">列出Mysql中有哪些数据库</h4>
<pre><code>sqoop list-databases \
-connect jdbc:mysql://localhost:3306/ \
-username root \
-password root
</code></pre>
<hr>
<h4 id="列出mysql中指定数据库的表">列出Mysql中指定数据库的表</h4>
<pre><code>sqoop list-tables \
-connect jdbc:mysql://localhost:3306/sqoop_test \
-username root \
-password root
</code></pre>
<hr>
<h4 id="创建一张跟sqoop_test库中user表结构一样的hive表hive_user">创建一张跟sqoop_test库中user表结构一样的hive表hive_user</h4>
<blockquote>
<p>此处需要将 hive 中的<code>hive-common-2.3.6.jar</code>包复制到 sqoop 的 lib 文件夹下，否则会报 <code>java.lang.ClassNotFoundException: org.apache.hadoop.hive.conf.HiveConf</code></p>
</blockquote>
<pre><code>sqoop create-hive-table \
-connect jdbc:mysql://localhost:3306/sqoop_test \
-username root \
-password root \
-table user \
-hive-table hive_user					#要创建的hive表名
</code></pre>
<p>创建完后可登录hive查看，以下为所执行的命令：</p>
<pre><code>hive												#登录Hive
show databases;								#查看数据库
use default;									#选择数据库,由于上面没有指定数据库，所以在默认数据库中创建了表
show tables;									#列出Default数据库中的所有表
</code></pre>
<hr>
<h4 id="mysqlhdfs从mysql导入到hdfs">Mysql→HDFS：从Mysql导入到HDFS</h4>
<pre><code>sqoop import \
-connect jdbc:mysql://{数据库IP}:3306/{数据库}?autoReconnect=true \		  #数据库连接
-driver com.mysql.jdbc.Driver	\														#数据库驱动
-username root	\																			#数据库用户名
-password root	\																			#数据库密码
-table user	\																				#数据库表
-target-dir	/user/admin/temp/sqoop-import	\										#导入到HDFS的目标目录
-fields-terminated-by ','	\															#按什么分隔
-m 1																							#MapReduce执行任务数
</code></pre>
<p>拓展命令（在导出中同样适用）：</p>
<pre><code>-where &quot;name = 'ZhangSan'&quot;																#带Where条件导入
-columns &quot;name&quot; 																			#导入指定列
#自定义Sql查询，导入查询后数据
-query 'select * from mysql.help_keyword where $CONDITIONS and name = &quot;STRING&quot;' 				
-split-by ‘id’																				#主键
-incremental  append  																	#增量导入
</code></pre>
<blockquote>
<p>在需要按照自定义SQL语句导出数据到HDFS的情况下👇👇：</p>
<ul>
<li>引号问题，要么外层使用单引号，内层使用双引号，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi><mi>O</mi><mi>N</mi><mi>D</mi><mi>I</mi><mi>T</mi><mi>I</mi><mi>O</mi><mi>N</mi><mi>S</mi><mi mathvariant="normal">的</mi></mrow><annotation encoding="application/x-tex">CONDITIONS的</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord cjk_fallback">的</span></span></span></span>符号不用转义， 要么外层使用双引号，那么内层使用单引号，然后<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi><mi>O</mi><mi>N</mi><mi>D</mi><mi>I</mi><mi>T</mi><mi>I</mi><mi>O</mi><mi>N</mi><mi>S</mi><mi mathvariant="normal">的</mi></mrow><annotation encoding="application/x-tex">CONDITIONS的</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord cjk_fallback">的</span></span></span></span>符号需要转义。</li>
<li>自定义的SQL语句中必须带有WHERE $CONDITIONS</li>
</ul>
</blockquote>
<hr>
<h4 id="hdfsmysql从hdfs中导出到mysql">HDFS→Mysql：从HDFS中导出到Mysql</h4>
<pre><code>sqoop export \
-connect jdbc:mysql://{数据库IP}:3306/{数据库}?autoReconnect=true \			 #数据库连接
-driver com.mysql.jdbc.Driver	\															#数据库驱动
-username root	\																				#数据库用户名
-password root	\																				#数据库密码
-table sqoop_test	\																			#数据库表
-export-dir	/user/admin/temp/sqoop-import	\											#导出HDFS的目标目录到Mysql
-fields-terminated-by ','	\																#按什么分隔
-split-by id	\																				#主键
-m 1																								#MapReduce执行任务数
</code></pre>
<blockquote>
<p>👨‍🏫记录问题👩‍🏫：</p>
<ul>
<li>若⭐️数据库连接或密码带上了 <code>$</code> 符号⭐️，则会导致后面语法报<strong>未找到命令错误</strong>；</li>
<li>有时需带上 <code>-driver</code>命令，否则<strong>有可能会</strong>导致出现数据库连接失败错误；</li>
<li>如果Mysql为8.0的版本，需要更改为8.0驱动包：<code>com.mysql.cj.jdbc.Driver</code></li>
<li>执行命令时必须带上<code>-split-by</code>或者<code>-m 1</code>命令，否则会报错；</li>
<li><code>-fields-terminated-by</code>命令表示 <strong>数据库中的列在导入文本中按照什么字符分隔</strong>，如上面例子中的 <strong>，</strong>;</li>
</ul>
</blockquote>
<hr>
<h4 id="mysqlhive从mysql导入到hive中">Mysql→Hive：从Mysql导入到Hive中</h4>
<blockquote>
<p><strong>导入过程：先导入到 hdfs，然后再 load 进入 hive😊</strong></p>
<p><strong>普通导入：数据存储在Hive默认的default库中，表名就是对应的mysql的表名：😜</strong></p>
</blockquote>
<pre><code>sqoop import   \
--connect jdbc:mysql://localhost:3306/sqoop_test   \			#数据库连接
--username root  \														#数据库用户名
--password root   \														#数据库密码
--table user   \															#数据库表
--hive-import \															#导入路径
-m 1																			#任务并发数
</code></pre>
<p>查看 Hive 中的数据</p>
<pre><code>hadoop fs -cat /user/hive/warehouse/user/part-m-00000			#user就是表名
</code></pre>
<p>拓展命令：</p>
<pre><code>-fields-terminated-by &quot;，&quot;  									#数据按什么分隔
-lines-terminated-by &quot;\n&quot;  									#行数按什么分隔
-hive-overwrite 													#指定覆盖导入
-create-hive-table  												#指定自动创建hive表
-delete-target-dir 												#指定删除中间结果数据目录
-hive-database  mydb_test 										#指定Hive数据库
-hive-table new_user												#指定表名
-incremental  append  											#增量导入
</code></pre>
<blockquote>
<p>当指定Hive数据库时，必须先创建该数据库，否则会报<code>Database does not exist: xx</code>数据库不存在🌈。</p>
<p>⚡️**从Hive导出到Mysql的步骤 和 从HDFS导出到Mysql的步骤 一致。**⚡️</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hadoop到Mysql的数据传输记录]]></title>
        <id>https://Yanoona.github.io/NNC7-_gM_/</id>
        <link href="https://Yanoona.github.io/NNC7-_gM_/">
        </link>
        <updated>2020-02-19T06:11:24.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="概述">概述</h2>
<p>本文档主要记录使用 <code>HIve Load</code> 将 <code>Hadoop</code> 中的文件保存到 <code>HIve</code> 的数据库中，再将其通过 <code>Sqoop export</code> 到 <code>Mysql</code> 的详细步骤🙊；</p>
]]></summary>
        <content type="html"><![CDATA[<h2 id="概述">概述</h2>
<p>本文档主要记录使用 <code>HIve Load</code> 将 <code>Hadoop</code> 中的文件保存到 <code>HIve</code> 的数据库中，再将其通过 <code>Sqoop export</code> 到 <code>Mysql</code> 的详细步骤🙊；</p>
<!-- more -->
<h2 id="环境及测试数据说明">环境及测试数据说明</h2>
<ul>
<li>Hadoop - 2.9.2</li>
<li>CentOS 7.9</li>
<li>Hive 2.3.9</li>
<li>Mysql 8.0</li>
<li>Sqoop 1.4.7</li>
<li>zy_fy_detail        659MB          5,691,514行</li>
<li>zy_fy_year          512KB           4,656行</li>
<li>zy_fy_yearmonth           59.59MB           516,883行</li>
<li>以上表的文本间隔符为 <code>\001</code></li>
</ul>
<h2 id="开始">开始</h2>
<h3 id="确认测试环境">确认测试环境</h3>
<ul>
<li>🌕使用<code>jps</code>查看 Hadoop 集群是否正常启动（包括<code>jobhistory</code>）</li>
<li>🌖使用<code>systemctl status mysqld</code>查看<code>Mysql</code>是否正常运行</li>
<li>🌗确认<code>hive</code>已经配置好了<code>mysql</code></li>
</ul>
<hr>
<h3 id="将测试数据上传到hadoop中">将测试数据上传到Hadoop中</h3>
<blockquote>
<p>上传文件可以自己搭建ftp服务器实现，或者使用hadoop中的网页上传功能。👏👏</p>
</blockquote>
<p><strong>此处使用Hadoop上传</strong>：</p>
<p>​		在浏览器除输入 http://hadoop1:50070:/，<em>hadoop1</em>为我这里的<em>NameNode</em>节点的主机名（如访问不了，可以试下换成IP访问😁）。点击 <em>Browse the file system</em> 进入目录页并单击红框处上传按钮。</p>
<figure data-type="image" tabindex="1"><img src="https://Yanoona.github.io/post-images/1582092792811.png" alt="" loading="lazy"></figure>
<p>如果出现以下类似信息🙄🙄（可以确定是<strong>权限问题</strong>）：</p>
<figure data-type="image" tabindex="2"><img src="https://Yanoona.github.io/post-images/1582092804261.png" alt="" loading="lazy"></figure>
<p>使用以下命令赋予权限后，就可以进行上传☝️、删除💀等操作：</p>
<pre><code>hadoop fs -chmod 777 /user/admin/*
</code></pre>
<hr>
<h3 id="创建接收数据的hive数据库">创建接收数据的Hive数据库</h3>
<p><strong>😋进入Hive，并创建数据库（此处示例数据库名：bigdata）</strong></p>
<pre><code>#进入Hive
hive
#显示数据库
show databases;
#创建数据库
create database bigdata;
#选择数据库
use bigdata;
</code></pre>
<p><strong>🙁创建可识别多个分隔符的表（zy_fy_year）</strong></p>
<pre><code> CREATE TABLE `zy_fy_year` (
       `year` varchar(4),
       `SFXM` decimal(4,0),
       `FYMC` varchar(160),
       `FYDJ` decimal(10,4),
       `year_sl` decimal(32,2),
       `year_ZJJE` decimal(34,2)
     )  row format  serde 'org.apache.hadoop.hive.contrib.serde2.MultiDelimitSerDe' with  serdeproperties (&quot;field.delim&quot;=&quot;&amp;*#@&quot;);

</code></pre>
<blockquote>
<p>Hive在0.14及以后版本支持字段的多分隔符，参考🚀<a href="https://link.jianshu.com/?t=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FHive%2FMultiDelimitSerDe">https://cwiki.apache.org/confluence/display/Hive/MultiDelimitSerDe</a>🚀</p>
<p>关键语句为👉：<code>row format serde 'org.apache.hadoop.hive.contrib.serde2.MultiDelimitSerDe' with serdeproperties (&quot;field.delim&quot;=&quot;你的分隔符&quot;);</code></p>
<p>当只有一个分隔符时👉：<code>row format delimited fields terminated by '分隔符'</code></p>
</blockquote>
<p>😎<strong>使用Hive Load加载HDFS文件到表中</strong></p>
<pre><code>#此处地址为Hadoop中zy_fy_year.txt文件的地址
load data inpath '/test_data/test_files/zy_fy_year.txt' overwirte into table bigdata.zy_fy_year
#查看插入结果是否有错
select * from zy_fy_year limit 0,10;
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://Yanoona.github.io/post-images/1582092825986.png" alt="" loading="lazy"></figure>
<hr>
<h3 id="使用sqoop将hive中的数据导出到mysql中">😉使用Sqoop将Hive中的数据导出到Mysql中</h3>
<p><strong>在Mysql创建导出数据库（bigdata）和表（zy_fy_year）🤗</strong></p>
<pre><code>#登录mysql
mysql -u root -p
#创建数据库
create database bigdata;
#选择数据库
use bigdata;
#创建表
create table `zy_fy_year` (
  `year` varchar(4) CHARACTER SET utf8mb4 DEFAULT NULL,
  `SFXM` decimal(4,0) NOT NULL COMMENT '收费项目',
  `FYMC` varchar(160) DEFAULT NULL COMMENT '费用名称',
  `FYDJ` decimal(10,4) NOT NULL COMMENT '费用单价',
  `year_sl` decimal(32,2) DEFAULT NULL COMMENT '年汇总数量',
  `year_ZJJE` decimal(34,2) DEFAULT NULL COMMENT '总计金额'
) engine=InnoDB default charset=utf8;
</code></pre>
]]></content>
    </entry>
</feed>